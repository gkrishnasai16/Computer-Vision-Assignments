{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import depthai as dai\n",
    "import numpy as np\n",
    "\n",
    "import time\n",
    "from pathlib import Path\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "img1 = cv2.imread('video_frames/17137219437727.png')\n",
    "img1 = cv2.cvtColor(img1, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "img2 = cv2.imread('video_frames/17137219432663.png')\n",
    "img2 = cv2.cvtColor(img2, cv2.COLOR_BGR2GRAY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1, y1 = 100, 100\n",
    "x2, y2 = 150, 150\n",
    "patch_size = 5\n",
    "\n",
    "patch_img1 = img1[y1-patch_size//2:y1+patch_size//2+1, x1-patch_size//2:x1+patch_size//2+1]\n",
    "patch_img2 = img2[y2-patch_size//2:y2+patch_size//2+1, x2-patch_size//2:x2+patch_size//2+1]\n",
    "\n",
    "# Display the selected patches\n",
    "cv2.imshow('Patch in Image 1', patch_img1)\n",
    "cv2.imshow('Patch in Image 2', patch_img2)\n",
    "cv2.waitKey(1000)\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Computing the SIFT feature for each of these 2 patches\n",
    "\n",
    "sift = cv2.SIFT_create() \n",
    "\n",
    "kp_img1, desc_img1 = sift.detectAndCompute(img1, None) \n",
    "kp_img2, desc_img2 = sift.detectAndCompute(img2, None) \n",
    "\n",
    "bf = cv2.BFMatcher()\n",
    "matches = bf.knnMatch(desc_img1, desc_img2, k=2)\n",
    "\n",
    "good_points=[]     \n",
    "for m, n in matches: \n",
    "    if(m.distance < 0.6*n.distance): \n",
    "        good_points.append(m) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SSD value: 11045979.0\n"
     ]
    }
   ],
   "source": [
    "# Filter descriptors based on matches\n",
    "matched_desc_img1 = np.array([desc_img1[m.queryIdx] for m in good_points])\n",
    "matched_desc_img2 = np.array([desc_img2[m.trainIdx] for m in good_points])\n",
    "\n",
    "# Compute the Sum of Squared Difference (SSD) between SIFT descriptors\n",
    "ssd_value = np.sum((matched_desc_img1 - matched_desc_img2) ** 2)\n",
    "print(\"SSD value:\", ssd_value)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_pts = np.float32([kp_img1[m.queryIdx] \n",
    "                .pt for m in good_points]).reshape(-1, 1, 2) \n",
    " \n",
    "train_pts = np.float32([kp_img2[m.trainIdx] \n",
    "                .pt for m in good_points]).reshape(-1, 1, 2) \n",
    " \n",
    "matrix, mask = cv2.findHomography(query_pts, train_pts, cv2.RANSAC, 5.0) \n",
    " \n",
    "matches_mask = mask.ravel().tolist() \n",
    "\n",
    "h,w = img1.shape\n",
    " \n",
    "pts = np.float32([ [0,0],[0,h-1],[w-1,h-1],[w-1,0] ]).reshape(-1,1,2)\n",
    " \n",
    "dst = cv2.perspectiveTransform(pts, matrix)\n",
    " \n",
    "homography = cv2.polylines(img2, [np.int32(dst)], True, (255, 0, 0), 3) \n",
    " \n",
    "cv2.imshow(\"Homography\", homography) \n",
    "cv2.imshow(\"Img\", img1) \n",
    "cv2.waitKey(1000)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 9.73705303e-01,  2.24858628e-02,  1.80161356e+01],\n",
       "       [-5.66427120e-03,  9.96127926e-01, -1.63754839e+00],\n",
       "       [-5.48952861e-05,  3.99859072e-05,  1.00000000e+00]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Homography matrix\n",
    "matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "img3 = cv2.drawMatches(img1, kp_img1, img2, kp_img2, good_points, None, flags=cv2.DrawMatchesFlags_NOT_DRAW_SINGLE_POINTS)\n",
    "cv2.imshow(\"lines\", img3)\n",
    "cv2.waitKey(1000)\n",
    "cv2.imwrite(\"homography.png\", img3)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inverse Homography Matrix:\n",
      "[[ 1.02583038e+00 -2.24129990e-02 -1.85182016e+01]\n",
      " [ 5.92535260e-03  1.00369168e+00  1.53684174e+00]\n",
      " [ 5.60763219e-05 -4.13638904e-05  9.98921986e-01]]\n"
     ]
    }
   ],
   "source": [
    "# Compute the inverse of the homography matrix\n",
    "inverse_matrix = np.linalg.inv(matrix)\n",
    "print(\"Inverse Homography Matrix:\")\n",
    "print(inverse_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
